{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import unittest\n",
    "from os import system, name\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# return the marks to be added and array after move\n",
    "def moveArray(array):\n",
    "    assert(len(array) == 4)\n",
    "    result = []\n",
    "    lastIsSumed = False\n",
    "    marksToBeAdded = 0\n",
    "    for num in array:\n",
    "        if num != 0:\n",
    "            if len(result) == 0:\n",
    "                result.append(num) \n",
    "            elif result[-1] == num:\n",
    "                if lastIsSumed:\n",
    "                    result.append(num)\n",
    "                    lastIsSumed = False\n",
    "                else:\n",
    "                    result[-1] += num\n",
    "                    marksToBeAdded += 2 * num\n",
    "                    lastIsSumed = True\n",
    "            else:\n",
    "                result.append(num)\n",
    "                lastIsSumed = False\n",
    "    result += [0] * (4 - len(result))\n",
    "    return marksToBeAdded, result\n",
    "\n",
    "# We define down and right as forward direction\n",
    "def getIthArrayInd(i, isRow, isForward):\n",
    "    margin = 1 if isRow else 4\n",
    "    direction = -1 if isForward else 1\n",
    "    return [i * (5 - margin) + j * margin for j in range(4)[::direction]]\n",
    "\n",
    "class Obj_2048:\n",
    "    \n",
    "    directions = {'Right' : (True, True), \n",
    "                 'Down': (False, True),\n",
    "                 'Left' : (True, False),\n",
    "                 'Up': (False, False)}\n",
    "    \n",
    "    def reset(self):\n",
    "        self._values = [0]*16\n",
    "        self._mark = 0\n",
    "        self._steps = 0\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def getMark(self):\n",
    "        return self._mark\n",
    "    \n",
    "    def getSteps(self):\n",
    "        return self._steps\n",
    "    \n",
    "    def getHighestNum(self):\n",
    "        return max(self._values)\n",
    "    \n",
    "    def _unpackArray(self, indList, array):\n",
    "        assert(len(indList) == 4)\n",
    "        for i in range(4):\n",
    "            self._values[indList[i]] = array[i]\n",
    "         \n",
    "    def _move(self,direction, isCheck):\n",
    "        isRow, isForward = Obj_2048.directions[direction]\n",
    "        marksToBeAdded = 0\n",
    "        canBeMoved = False\n",
    "        for i in range(4):\n",
    "            indList = getIthArrayInd(i, isRow, isForward)\n",
    "            array = [self._values[ind] for ind in indList]\n",
    "            mark, result = moveArray(array)\n",
    "            #means something changed\n",
    "            if (array != result):\n",
    "                canBeMoved = True                          \n",
    "                #if it is a player's action, change the values\n",
    "                if not isCheck:\n",
    "                    print(array)\n",
    "                    print(result)\n",
    "                    print(indList)\n",
    "                    print(str(i) + \" above\")\n",
    "                    self._unpackArray(indList,result)\n",
    "                marksToBeAdded += mark\n",
    "        if (not isCheck) and canBeMoved:\n",
    "            self._mark += marksToBeAdded\n",
    "            self._steps += 1\n",
    "        return canBeMoved\n",
    "        \n",
    "    def _isGameOver(self):\n",
    "        for direction in Obj_2048.directions.keys():\n",
    "            if (self._move(direction, True)):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _generateNext(self):\n",
    "        tmp = []\n",
    "        adj = [-4, -1 , 1, 4]\n",
    "        for i in range(16):\n",
    "            okToGenerate = False\n",
    "            for j in adj:\n",
    "                if i + j >= 16 or i + j < 0 or self._values[i] != 0:\n",
    "                    okToGenerate = True\n",
    "                    break\n",
    "            if okToGenerate:\n",
    "                tmp.append(i)\n",
    "        self._values[tmp[randint(0,len(tmp) - 1)]] = 2 * (randint(0,1) + 1)\n",
    "                    \n",
    "    def play(self):\n",
    "        ##get first 2 nums\n",
    "        self._generateNext()\n",
    "        self._generateNext()\n",
    "        while(not self._isGameOver()):\n",
    "            for i in range(4):\n",
    "                print(self._values[i * 4: i * 4 + 4])\n",
    "            print(\"marks: \" + str(self._mark))\n",
    "            print(\"moves: \" + str(self._steps))\n",
    "            direction = input(\"Enter next move:\")\n",
    "            clear_output(wait=True)\n",
    "            if (direction == \"exit\"):\n",
    "                break\n",
    "            if (direction in Obj_2048.directions.keys()):\n",
    "                if self._move(direction, False):\n",
    "                    self._generateNext()\n",
    "            else:\n",
    "                print('\\x1b[6;30;42m' + \"Please input one of \\\"Right, Up, Down, Left\\\"\" + '\\x1b[0m', end = \"\\r\")\n",
    "        print(\"Game Over\")\n",
    "        print(\"marks: \" + str(self._mark))\n",
    "        print(\"moves: \" + str(self._steps))\n",
    "        print(\"highest: \" + str(self.getHighestNum()))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 2]\n",
      "[2, 0, 0, 0]\n",
      "[1, 5, 9, 13]\n",
      "1 above\n",
      "[4, 2, 0, 8]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "marks: 16\n",
      "moves: 4\n"
     ]
    }
   ],
   "source": [
    "game = Obj_2048()\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import random \n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sunt9\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\sunt9\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#first convolution layer depth\n",
    "depth1 = 128\n",
    "\n",
    "#second convolution layer depth\n",
    "depth2 = 128\n",
    "\n",
    "#batch size for batch gradient descent\n",
    "batch_size = 512\n",
    "\n",
    "#input units\n",
    "input_units = 16\n",
    "\n",
    "#fully connected layer neurons\n",
    "hidden_units = 256\n",
    "\n",
    "#output neurons = number of moves\n",
    "output_units = 4\n",
    "\n",
    "\n",
    "#hyper parameters\n",
    "start_learning_rate = 0.0005\n",
    "\n",
    "#gamma for Q-learning\n",
    "gamma = 0.9\n",
    "\n",
    "#epsilon greedy approach\n",
    "epsilon = 0.9\n",
    "\n",
    "#to store states and lables of the game for training\n",
    "#states of the game\n",
    "replay_memory = list()\n",
    "\n",
    "#labels of the states\n",
    "replay_labels = list()\n",
    "\n",
    "#capacity of memory\n",
    "mem_capacity = 6000\n",
    "\n",
    "#deprecated method \n",
    "#todo: fix placeholder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "#input data\n",
    "tf_batch_dataset = tf.placeholder(tf.float32,shape=(batch_size,4,4,16))\n",
    "tf_batch_labels  = tf.placeholder(tf.float32,shape=(batch_size,output_units))\n",
    "\n",
    "single_dataset   = tf.placeholder(tf.float32,shape=(1,4,4,16))\n",
    "\n",
    "#CONV LAYERS\n",
    "#conv layer1 weights\n",
    "conv1_layer1_weights = tf.Variable(tf.truncated_normal([1,2,input_units,depth1],mean=0,stddev=0.01))\n",
    "conv2_layer1_weights = tf.Variable(tf.truncated_normal([2,1,input_units,depth1],mean=0,stddev=0.01))\n",
    "\n",
    "#conv layer2 weights\n",
    "conv1_layer2_weights = tf.Variable(tf.truncated_normal([1,2,depth1,depth2],mean=0,stddev=0.01))\n",
    "conv2_layer2_weights = tf.Variable(tf.truncated_normal([2,1,depth1,depth2],mean=0,stddev=0.01))\n",
    "\n",
    "#FUllY CONNECTED LAYERS\n",
    "expand_size = 2*4*depth2*2 + 3*3*depth2*2 + 4*3*depth1*2\n",
    "fc_layer1_weights = tf.Variable(tf.truncated_normal([expand_size,hidden_units],mean=0,stddev=0.01))\n",
    "fc_layer1_biases = tf.Variable(tf.truncated_normal([1,hidden_units],mean=0,stddev=0.01))\n",
    "fc_layer2_weights = tf.Variable(tf.truncated_normal([hidden_units,output_units],mean=0,stddev=0.01))\n",
    "fc_layer2_biases = tf.Variable(tf.truncated_normal([1,output_units],mean=0,stddev=0.01))\n",
    "\n",
    "#model\n",
    "def model(dataset):\n",
    "    #layer1\n",
    "    conv1 = tf.nn.conv2d(dataset,conv1_layer1_weights,[1,1,1,1],padding='VALID') \n",
    "    conv2 = tf.nn.conv2d(dataset,conv2_layer1_weights,[1,1,1,1],padding='VALID') \n",
    "    \n",
    "    #layer1 relu activation\n",
    "    relu1 = tf.nn.relu(conv1)\n",
    "    relu2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    #layer2\n",
    "    conv11 = tf.nn.conv2d(relu1,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "    conv12 = tf.nn.conv2d(relu1,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "\n",
    "    conv21 = tf.nn.conv2d(relu2,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "    conv22 = tf.nn.conv2d(relu2,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "\n",
    "    #layer2 relu activation\n",
    "    relu11 = tf.nn.relu(conv11)\n",
    "    relu12 = tf.nn.relu(conv12)\n",
    "    relu21 = tf.nn.relu(conv21)\n",
    "    relu22 = tf.nn.relu(conv22)\n",
    "    \n",
    "    #get shapes of all activations\n",
    "    shape1 = relu1.get_shape().as_list()\n",
    "    shape2 = relu2.get_shape().as_list()\n",
    "    \n",
    "    shape11 = relu11.get_shape().as_list()\n",
    "    shape12 = relu12.get_shape().as_list()\n",
    "    shape21 = relu21.get_shape().as_list()\n",
    "    shape22 = relu22.get_shape().as_list()\n",
    "\n",
    "    #expansion\n",
    "    hidden1 = tf.reshape(relu1,[shape1[0],shape1[1]*shape1[2]*shape1[3]])\n",
    "    hidden2 = tf.reshape(relu2,[shape2[0],shape2[1]*shape2[2]*shape2[3]])\n",
    "    \n",
    "    hidden11 = tf.reshape(relu11,[shape11[0],shape11[1]*shape11[2]*shape11[3]])\n",
    "    hidden12 = tf.reshape(relu12,[shape12[0],shape12[1]*shape12[2]*shape12[3]])\n",
    "    hidden21 = tf.reshape(relu21,[shape21[0],shape21[1]*shape21[2]*shape21[3]])\n",
    "    hidden22 = tf.reshape(relu22,[shape22[0],shape22[1]*shape22[2]*shape22[3]])\n",
    "\n",
    "    #concatenation\n",
    "    hidden = tf.concat([hidden1,hidden2,hidden11,hidden12,hidden21,hidden22],axis=1)\n",
    "\n",
    "    #full connected layers\n",
    "    hidden = tf.matmul(hidden,fc_layer1_weights) + fc_layer1_biases\n",
    "    hidden = tf.nn.relu(hidden)\n",
    "\n",
    "    #output layer\n",
    "    output = tf.matmul(hidden,fc_layer2_weights) + fc_layer2_biases\n",
    "    \n",
    "    #return output\n",
    "    return output\n",
    "\n",
    "#for single example\n",
    "single_output = model(single_dataset)\n",
    "\n",
    "#for batch data\n",
    "logits = model(tf_batch_dataset)\n",
    "\n",
    "#loss\n",
    "loss = tf.square(tf.subtract(tf_batch_labels,logits))\n",
    "loss = tf.reduce_sum(loss,axis=1,keep_dims=True)\n",
    "loss = tf.reduce_mean(loss)/2.0\n",
    "\n",
    "#optimizer\n",
    "global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "learning_rate = tf.train.exponential_decay(float(start_learning_rate), global_step, 1000, 0.90, staircase=True)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "J = []\n",
    "\n",
    "#scores\n",
    "scores = []\n",
    "\n",
    "#to store final parameters\n",
    "final_parameters = {}\n",
    "\n",
    "#number of episodes\n",
    "M = 200001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
